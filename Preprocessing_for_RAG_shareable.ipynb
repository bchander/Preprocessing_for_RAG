{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code to preprocess input pdf file to differentiate the tabular data and help extract its structured information without losing it like how we observe in traditional RAG splitted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.....Importing necessary libraries....#\n",
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import fitz\n",
    "from openai import OpenAI\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''.....Addon Ideas/trials that you can try\n",
    "1. I've tested with just GPT-4o, try other multimodals, including Gemini\n",
    "2. I've passed the entire context (text + all extracted images), you can consider having chuncks/splits for the text data to be retrievable \n",
    "    - instead of passing entire context and see if it can impact accuracy. You can try the feasibility of this combination.\n",
    "3. In future, we can try the linkeage between the text and the connected images. There may be mention of table information somwhere in the text\n",
    "    and the current approach of (text + images) might be loosing this information. We can explore a simple way of retaining this linkeage between text block and the connected images\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.....Importing Model credentials....#\n",
    "# I've used my personal credentials for testing. You can change the client to use Azure endpoints (as done in most of our projects)\n",
    "# Also, recommend other multimodals (like Gemini 1.5 Pro) or Vision Modles (like LLaVA)  \n",
    "\n",
    "gpt_model = 'YOUR_GPT_MODEL' #'gpt-4o-mini-2024-07-18' #'gpt-3.5-turbo-1106' #'gpt-3.5-turbo-0613' \n",
    "client = OpenAI(api_key = \"YOUR_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text and find pages with tables\n",
    "def extract_text_and_find_table_pages(pdf_path):\n",
    "    \"\"\"Extract text and identify pages containing tables.\"\"\"\n",
    "    table_pages = []\n",
    "    text_data = {}\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text()\n",
    "            tables = page.extract_tables()\n",
    "            \n",
    "            if tables and any(any(cell for cell in row) for table in tables for row in table):\n",
    "                table_pages.append(i + 1)  # Page numbers start from 1\n",
    "\n",
    "            text_data[i + 1] = text if text else \"\"  # Store text data\n",
    "\n",
    "    return text_data, table_pages\n",
    "\n",
    "#....Function to convert pages (that contain tables) to images....#\n",
    "def convert_table_pages_to_images(pdf_path, table_pages, output_folder):\n",
    "    \"\"\"Convert table pages to images and save them.\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    for page_num in table_pages:\n",
    "        page = doc[page_num - 1]\n",
    "        pix = page.get_pixmap(dpi=300)  # Higher DPI for clarity\n",
    "        img_path = os.path.join(output_folder, f\"page_{page_num}.png\")\n",
    "        pix.save(img_path)\n",
    "        print(f\"Saved table page {page_num} as image.\")\n",
    "\n",
    "    return output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved table page 1 as image.\n",
      "Saved table page 2 as image.\n",
      "Saved table page 3 as image.\n",
      "Saved table page 5 as image.\n",
      "Saved table page 6 as image.\n",
      "Saved table page 7 as image.\n",
      "Saved table page 8 as image.\n",
      "Saved table page 9 as image.\n",
      "Saved table page 10 as image.\n",
      "Saved table page 11 as image.\n",
      "Saved table page 12 as image.\n",
      "Saved table page 13 as image.\n"
     ]
    }
   ],
   "source": [
    "# Path to Input file \n",
    "uploaded_file = r\"PATH_TO_INPUT_FILE\"\n",
    "# NOTE: I've built the application considering input and ooutputs to local machine only. For deployments consider using saved file URLs\n",
    "\n",
    "#Path to folder that stores the extracted pages of the pdf that shall be saved as images in the folder  \n",
    "output_folder = r\"LOCAL_FOLDER_PATH_TO_STORE_CONVERTED_IMAGES\"\n",
    "\n",
    "# Extracting page numbers of pdfs that contains tables, along with text data. Here i'm not oing to use 'text_data' but just included it FYR\n",
    "text_data, table_pages = extract_text_and_find_table_pages(uploaded_file)\n",
    "\n",
    "if table_pages:\n",
    "    convert_table_pages_to_images(uploaded_file, table_pages, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#....Defining the Prompt, customize this based on your application.....#\n",
    "input_prompt = \"\"\"Identify the specifications from the provided document context and set of images. Extract the values for the identified specifications from the context and all the input images. \n",
    "                      Provide the extracted specifications from the provided context in a structured JSON format. Each specification should have an value entry. \n",
    "                      The values should also include the associated units if available. If a specification is missing, include 'N/A' for that entry.\n",
    "                      The first two entires of the specification should be 'company' and 'product/Model Number'. Extract as many specifications as possible from the provided contexts.\n",
    "                      If the fetched values has any special characters like backslash etc., convert the values such that it will not create any issues while parsing the JSON. \n",
    "                      If the extracted value for any specification is in nested format, convert them into a list of key value pair and stick to the required format of JSON. Don't output in nested json format. Don't use same keys again and again, but instead merge similar key information into a list of strings.\n",
    "                      Format your response as: \n",
    "                      {\n",
    "                        \"company\": [\"Value from context1\"],\n",
    "                        \"product/Model Number\": [\"Value from context1\"],\n",
    "                        \"Specification 3\": [\"Value from context1\"], \n",
    "                        \"Specification 4\": [\"Value from context1\"], \n",
    "                        ... \n",
    "                      }\n",
    "                      \n",
    "                      \"\"\" \n",
    "\n",
    "#I was trying to extract specification from datasheets and the above prompt worked well for me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert an image file to base64. GPT needs to image to be convereted to bytes\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Function to extract specs from the input datasheet text\n",
    "def extract_specs(pdf_text: str, input_prompt: str, image_files: list) -> str:\n",
    "    # pdf_text: extracted text for the pages of the pdf that deosn't contain tables\n",
    "    # image_files: List of images as found in the image folder\n",
    "    \n",
    "    # Defining the message that will be later appended with image information\n",
    "    messages = [ {\"role\": \"assistant\", \"content\": input_prompt},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"Context: {pdf_text}\"}\n",
    "                ]},\n",
    "                #   {\"role\": \"user\", \"content\": query_text}\n",
    "                ]\n",
    "    \n",
    "    # Convert and add images to API request\n",
    "    for image_path in image_files:\n",
    "        base64_image = encode_image(image_path)\n",
    "        messages[1][\"content\"].append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}  # Use base64-encoded image\n",
    "        })\n",
    "\n",
    "    # .....Generating the responses using the extracted pdf text and the images that contain tables......#\n",
    "    response = client.chat.completions.create(\n",
    "        model=gpt_model, \n",
    "        messages = messages, #prompt=prompt_template,\n",
    "        max_tokens=1200,\n",
    "        temperature = 0.1,\n",
    "    )\n",
    "    specifications = response.choices[0].message.content\n",
    "    return specifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from the pages of the pdf that doesn't contain tables\n",
    "def extract_text_from_pdf(file) -> str:\n",
    "    pdf_reader = fitz.open(file)\n",
    "    full_text = \"\"\n",
    "    page_texts = []\n",
    "    # for page_num in range(pdf_reader.getNumPages()):\n",
    "    for page_num in range(pdf_reader.page_count):\n",
    "        if (page_num + 1) not in table_pages:  # Skip table pages\n",
    "            page = pdf_reader[page_num]\n",
    "            # text = page.get_text(\"text\") \n",
    "            blocks = page.get_text(\"blocks\") \n",
    "            # Blocks can: Extracts text in structured blocks (preserving layout), Keeps text in blocks (helps preserve meaning), \n",
    "            #             Replaces \\n with spaces for non-heading content, Ensures headings or key-value pairs stay structured, More control over structuring output\n",
    "\n",
    "            processed_blocks = []\n",
    "            for b in blocks:\n",
    "                block_text = b[4].strip()\n",
    "                if block_text:\n",
    "                    if \":\" in block_text:\n",
    "                        processed_blocks.append(block_text)\n",
    "                    else:\n",
    "                        processed_blocks.append(block_text.replace(\"\\n\", \" \"))\n",
    "            processed_text = \"\\n\".join(processed_blocks)\n",
    "            full_text += processed_text + \"\\n\\n\"\n",
    "            page_texts.append(processed_text)\n",
    "    return page_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"company\": [\"ABB\"],\n",
      "  \"product/Model Number\": [\"ITABB-RR3595\"],\n",
      "  \"Document No\": [\"ITABB-RR3595\"],\n",
      "  \"Doc. version\": [\"Original - Approved - Lean\"],\n",
      "  \"Risk review number\": [\"ITABB-RR3595\"],\n",
      "  \"External Doc Number (ABB SalesForce)\": [\"0063Y00001szH6uQAE\"],\n",
      "  \"Opportunity Id\": [\"OPP-23-6138578\"],\n",
      "  \"Project name\": [\"AEN Compensatori Sincroni Terna 2023 Lotto 3\"],\n",
      "  \"Customer is ABB unit?\": [\"No\"],\n",
      "  \"Customer\": [\"G08036496, Ansaldo Energia S.p.A., Genova, IT\"],\n",
      "  \"Customer country CPI\": [\"IT/Lower\"],\n",
      "  \"Customer at Submission\": [\"G08036496, Ansaldo Energia S.p.A., Genova, IT\"],\n",
      "  \"Customer at Submission country CPI\": [\"IT/Lower\"],\n",
      "  \"Customer region\": [\"Europe\"],\n",
      "  \"End user\": [\"G00121821, Terna S.p.A., Roma, IT\"],\n",
      "  \"End user country CPI\": [\"IT/Lower\"],\n",
      "  \"End user at Submission\": [\"G00121821, Terna S.p.A., Roma, IT\"],\n",
      "  \"End user at Submission country CPI\": [\"IT/Lower\"],\n",
      "  \"End user region\": [\"Europe\"],\n",
      "  \"Site country, exact geographic location\": [\"IT\"],\n",
      "  \"Site country CPI\": [\"IT/Lower\"],\n",
      "  \"Site country at Submission\": [\"IT\"],\n",
      "  \"Site country at Submission CPI\": [\"IT/Lower\"],\n",
      "  \"Tender responsible\": [\"Enrico Grasso/IT\"],\n",
      "  \"Tendering unit\": [\"ITABB IA IAEN 4378 - IAEN Automation & Electrification Solutions\"],\n",
      "  \"Tendering unit at submission\": [\"ITABB IA IAEN 4378 - IAEN Automation & Electrification Solutions\"],\n",
      "  \"Tendering unit region\": [\"Europe\"],\n",
      "  \"HUB\": [\"PGH_IAEN__Central & Southern Europe\"],\n",
      "  \"HUB at Submission\": [\"PGH_IAEN__Central & Southern Europe\"],\n",
      "  \"End user industry usage\": [\"UT.1.9 - Other Sources\"],\n",
      "  \"Tender type\": [\"System\", \"Product\"],\n",
      "  \"Related to FA/BW\": [\"N/A\"],\n",
      "  \"Consortium\": [\"No\"],\n",
      "  \"Split revenue\": [\"No\"],\n",
      "  \"Estimated bid value incl. consortium\": [\"680 kUSD\"],\n",
      "  \"External system Id\": [\"9AAG10077\"],\n",
      "  \"Due date\": [\"2023-06-30\", \"2023-12-22\"],\n",
      "  \"Estimated contract/FA award date\": [\"2023-12-20\", \"2024-03-03\"],\n",
      "  \"Actual contract/FA award date\": [\"N/A\"],\n",
      "  \"Front End Sales / Group Account Manager\": [\"Enrico Grasso/IT\"],\n",
      "  \"Project manager\": [\"N/A\"],\n",
      "  \"Project status\": [\"Tendering\"],\n",
      "  \"Business type\": [\"Energy Solution (except Nuclear & Coal)\"],\n",
      "  \"Cost currency\": [\"EUR\"],\n",
      "  \"Total Net Sales Price\": [\"665\"],\n",
      "  \"Production Costs\": [\"529\"],\n",
      "  \"Contingencies\": [\"13\"],\n",
      "  \"Risk Provisions\": [\"3\"],\n",
      "  \"Gross result\": [\"120\"],\n",
      "  \"Sales, general and administration, and other fees/costs\": [\"63\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of image files\n",
    "image_files = [os.path.join(output_folder, img) for img in sorted(os.listdir(output_folder)) if img.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "# Extracting the text of the input pdf for the pages that doesn't contain tables\n",
    "pdf_text = extract_text_from_pdf(uploaded_file)\n",
    "\n",
    "# Generating the response by calling LLM model\n",
    "specifications = extract_specs(pdf_text, input_prompt, image_files)\n",
    "\n",
    "# Printing the extracted information\n",
    "print(specifications)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
